# ğŸ¤– Chatbot SLA & Productivity Analytics  

**Autor:** Franklin Santana dos Santos  
**Linguagem:** SQL (Databricks / Spark SQL)  
**TÃ³pico:** AnÃ¡lise de performance operacional e atendimento via chat  

---

## ğŸ Objetivo  

Desenvolver uma anÃ¡lise completa da performance de atendimento via **chatbot e agentes humanos**, avaliando:  
- volume de tickets oferecidos e tratados;  
- produtividade por agente e por fila;  
- cumprimento de SLA;  
- tempos mÃ©dios de resposta e atendimento;  
- backlog acumulado por faixa de tempo.  

O projeto visa mensurar **eficiÃªncia operacional** e identificar **gargalos no fluxo de atendimento digital**.

---

## ğŸ§© Fontes de Dados  

| Fonte | DescriÃ§Ã£o |
|-------|------------|
| `analytics.chatbot_interactions` | InteraÃ§Ãµes entre clientes e chatbot, incluindo tipo de aÃ§Ã£o e produtividade. |
| `analytics.chat_sessions` | SessÃµes de atendimento de chat, com timestamps de inÃ­cio, fim e resposta do agente. |
| `support.ticket_group_history` | HistÃ³rico de tickets por fila e momento de entrada. |
| `support.ticket_details` | Detalhes adicionais sobre cada ticket (canal, produto, segmento etc). |

---

## âš™ï¸ Principais TÃ©cnicas SQL Utilizadas  

- **CTEs (Common Table Expressions)** para estruturar o pipeline de anÃ¡lise;  
- **FunÃ§Ãµes de janela** (`row_number()`, `lead()`) para identificar aÃ§Ãµes e sessÃµes relevantes;  
- **Case statements dinÃ¢micos** para granularidade diÃ¡ria, semanal e mensal;  
- **ConversÃ£o de timestamps** com `unix_timestamp()` e cÃ¡lculo de minutos de atendimento;  
- **Filtros condicionais com `FILTER (WHERE ...)`** para medir SLA e backlog;  
- **Limpeza e deduplicaÃ§Ã£o** de dados de sessÃµes e tickets.  

---

## ğŸ§® MÃ©tricas Calculadas  

| MÃ©trica | DescriÃ§Ã£o |
|----------|------------|
| **handled** | Quantidade de tickets tratados. |
| **productive_actions** | Total de aÃ§Ãµes produtivas realizadas. |
| **productivity_per_agent** | MÃ©dia de aÃ§Ãµes produtivas por agente. |
| **avg_response_time** | Tempo mÃ©dio de resposta (em minutos). |
| **avg_handling_time** | Tempo mÃ©dio de atendimento do agente. |
| **sla_compliance** | Volume de tickets atendidos dentro do SLA. |
| **backlog_24h / 48h / 72h / +72h** | Volume de tickets pendentes em cada janela de tempo. |
| **avg_total_handling_time** | Tempo mÃ©dio total de tratamento por ticket oferecido. |

---

## ğŸ“ˆ Exemplo de Resultados  

| Dia | Tickets Oferecidos | SLA Compliance (%) | Produtividade por Agente | Tempo MÃ©dio de Atendimento (min) | Backlog +72h |
|-----|--------------------|--------------------|----------------------------|----------------------------------|--------------|
| 2025-03-01 | 1.240 | 87% | 42,3 | 18,5 | 34 |
| 2025-03-02 | 1.130 | 84% | 38,9 | 19,8 | 49 |
| 2025-03-03 | 1.550 | 91% | 44,1 | 17,2 | 27 |

*(dados ilustrativos)*

---

## ğŸ’¼ Insights de NegÃ³cio  

- O tempo mÃ©dio de atendimento (TMA) mantÃ©m-se abaixo de **20 minutos**, indicando boa eficiÃªncia.  
- O cumprimento de **SLA** estÃ¡ entre **84â€“91%**, mas oscila em perÃ­odos de pico.  
- A fila **â€œComplaintsâ€** apresenta o maior backlog acima de 72h, sugerindo redistribuiÃ§Ã£o de headcount.  
- A mÃ©trica **handled_per_agent** mostra correlaÃ§Ã£o direta com produtividade geral.  

---

## ğŸ§° Tecnologias Utilizadas  

- **SQL (Spark / Databricks)**  
- **Azure Databricks Workspace**  
- **Google Sheets + Looker Studio** para visualizaÃ§Ã£o dos resultados  

---

## ğŸ§± Estrutura do RepositÃ³rio  


ğŸ“ chatbot-sla-performance-analysis/
 â”œâ”€â”€ query.sql
 â”œâ”€â”€ README.md
 â”œâ”€â”€ sample_results.csv
 â””â”€â”€ dashboard_preview.png


---

## ğŸš€ PrÃ³ximos Passos  

1. Automatizar exportaÃ§Ã£o dos resultados para **Google Sheets** via Python;  
2. Criar **dashboard no Looker Studio** para acompanhamento visual;  
3. Adicionar comparaÃ§Ã£o histÃ³rica (MÃªs vs MÃªs) e anÃ¡lise de sazonalidade;  
4. Publicar artigo no **LinkedIn** explicando o raciocÃ­nio e o impacto dos resultados.  

---

## ğŸ§  ObservaÃ§Ã£o TÃ©cnica  

A query foi projetada para rodar em **ambiente Databricks (Spark SQL)** e utiliza parÃ¢metros dinÃ¢micos:  
- `:granularity` â†’ define o nÃ­vel de agrupamento (`Day`, `Week`, `Month`);  
- `:date.min` / `:date.max` â†’ intervalos de data;  

Esses parÃ¢metros permitem que a anÃ¡lise seja flexÃ­vel e aplicÃ¡vel em diferentes perÃ­odos.

---

## ğŸ“ Contato  

ğŸ‘¤ **Franklin Santana dos Santos**  
ğŸ”— [GitHub - franklinsts](https://github.com/franklinsts)  
ğŸ’¼ Analista de Customer Experience SÃªnior â€¢ Foco em AnÃ¡lise de Dados  
ğŸ“Š SQL | Databricks | Looker Studio | Google Sheets | AutomaÃ§Ã£o de dados  

--- 
